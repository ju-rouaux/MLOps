{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code pour mettre et récupérer un model sur docker \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Chargement et préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_and_prepare_data(directory_path):\n",
    "    \"\"\"Charge les fichiers JSON et prépare les données pour la vectorisation.\"\"\"\n",
    "    combined_data = {}\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                combined_data.update(data)\n",
    "\n",
    "    # Extraire les champs pertinents\n",
    "    texts = [content.get('readme_clean', '') for content in combined_data.values()]\n",
    "    labels = [content['mainLanguage'] for content in combined_data.values()]\n",
    "\n",
    "    # Encodage des labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "    return texts, encoded_labels, label_encoder\n",
    "\n",
    "# Charger et préparer les données\n",
    "texts, labels, label_encoder = load_and_prepare_data(directory_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokeniser les textes\n",
    "tokenized_texts = [word_tokenize(text) for text in texts]\n",
    "\n",
    "# Entraîner le modèle Word2Vec\n",
    "word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Fonction pour obtenir un vecteur moyen par document\n",
    "def vectorize_documents(tokenized_texts, model):\n",
    "    \"\"\"Vectorise une liste de documents tokenisés en utilisant Word2Vec.\"\"\"\n",
    "    document_vectors = []\n",
    "    for tokens in tokenized_texts:\n",
    "        vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "        if vectors:\n",
    "            document_vectors.append(sum(vectors) / len(vectors))\n",
    "        else:\n",
    "            document_vectors.append([0] * model.vector_size)  # Vecteur nul si aucun mot n'est trouvé\n",
    "    return document_vectors\n",
    "\n",
    "# Vectoriser les documents\n",
    "document_vectors = vectorize_documents(tokenized_texts, word2vec_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données\n",
    "X_train, X_test, y_train, y_test = train_test_split(document_vectors, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Modèle et classifieur et Connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle entrainé\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log le modèle (autrement dit le mettre sur Mlflow Docker)\n",
    "# Enregistrer les modèles avec un run parent\n",
    "with mlflow.start_run(run_name=\"model_training\") as parent_run:\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"random_forest\", nested=True):\n",
    "        mlflow.sklearn.log_model(clf, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple pour charger un modèle depuis un run spécifique\n",
    "run_id = '488f4afcbc1b46729f39b792c87bb08d'  # Remplacez par l'ID du run que vous souhaitez inspecter\n",
    "logged_model = f'runs:/{run_id}/random_forest_model'\n",
    "\n",
    "# Charger le modèle\n",
    "model = mlflow.sklearn.load_model(logged_model)\n",
    "\n",
    "# Vérifier si le modèle est chargé correctement\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplace <RUN_ID> par l'ID du run où est enregistré le modèle qu'on veut charger puis nom de lui\n",
    "model = mlflow.sklearn.load_model(f\"runs:/5fefbe6797a24f0fafc544605ae42970/son_nom\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "test_input = np.random.rand(1, model.n_features_in_)  # Crée un input avec le bon nombre de colonnes\n",
    "prediction = model.predict(test_input)\n",
    "\n",
    "print(\"Prédiction :\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
