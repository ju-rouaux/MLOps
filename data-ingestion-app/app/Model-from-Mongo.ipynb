{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Entrainement de modèle depuis les données mongoDB vers MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pymongo\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion à MongoDB\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")  \n",
    "db = client.get_database(\"dev\")\n",
    "collection = db.get_collection(\"raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données depuis MongoDB\n",
    "def load_data_from_mongo():\n",
    "    data = list(collection.find())\n",
    "    texts = [item.get(\"readme_clean\", \"\") for item in data]\n",
    "    labels = [item.get(\"mainLanguage\", \"\") for item in data]\n",
    "    return texts, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger et préparer les données\n",
    "texts, labels = load_data_from_mongo()\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Tokenisation des textes\n",
    "tokenized_texts = [word_tokenize(text) for text in texts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle Word2Vec\n",
    "word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour vectoriser les documents\n",
    "def vectorize_documents(tokenized_texts, model):\n",
    "    document_vectors = []\n",
    "    for tokens in tokenized_texts:\n",
    "        vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "        if vectors:\n",
    "            document_vectors.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            document_vectors.append(np.zeros(model.vector_size))\n",
    "    return document_vectors\n",
    "\n",
    "document_vectors = vectorize_documents(tokenized_texts, word2vec_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(document_vectors, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du classifieur\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:8090\")\n",
    "\n",
    "# Enregistrement du modèle dans MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.sklearn.log_model(classifier, \"random_forest_model\")\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "\n",
    "print(\"Modèle entraîné et enregistré dans MLflow !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
