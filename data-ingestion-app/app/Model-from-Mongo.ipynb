{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Entrainement de mod√®le depuis les donn√©es mongoDB vers MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pymongo\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pyspark.sql.types import StructType, StructField, StringType, MapType, TimestampType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+----------------+------------+\n",
      "|                user|                repo|           languages|              readme|processed_readme|last_updated|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------------+------------+\n",
      "|               folke|        trouble.nvim|{Shell -> 117, Lu...|# üö¶ Trouble\\n\\nA...|            NULL|        NULL|\n",
      "|               folke|      which-key.nvim|{Shell -> 119, Lu...|# üí• Which Key\\n\\...|            NULL|        NULL|\n",
      "|              lsyncd|              lsyncd|{Shell -> 1275, L...|Lsyncd -- Live Sy...|            NULL|        NULL|\n",
      "|           lewis6991|       gitsigns.nvim|{Makefile -> 2663...|# gitsigns.nvim\\n...|            NULL|        NULL|\n",
      "|            LunarVim| Neovim-from-scratch|      {Lua -> 58070}|# Neovim from scr...|            NULL|        NULL|\n",
      "|             lite-xl|             lite-xl|{Shell -> 18333, ...|# Lite XL\\n\\n[![C...|            NULL|        NULL|\n",
      "|             epwalsh|       obsidian.nvim|{Shell -> 498, Vi...|<h1 align=\"center...|            NULL|        NULL|\n",
      "|               folke|          noice.nvim|{Shell -> 52, Lua...|# üí• Noice _(Nice...|            NULL|        NULL|\n",
      "|         liuzhuang13|            DenseNet|      {Lua -> 61862}|# Densely Connect...|            NULL|        NULL|\n",
      "|            stevearc|            oil.nvim|{Shell -> 867, Vi...|# oil.nvim\\n\\nA [...|            NULL|        NULL|\n",
      "|             rebelot|       kanagawa.nvim|{Shell -> 1206, V...|<p align=\"center\"...|            NULL|        NULL|\n",
      "|             akinsho|     toggleterm.nvim|      {Lua -> 92552}|<!-- panvimdoc-ig...|            NULL|        NULL|\n",
      "|PathOfBuildingCom...|      PathOfBuilding|{Dockerfile -> 17...|# Path of Buildin...|            NULL|        NULL|\n",
      "|       lukas-reineke|indent-blankline....|{Makefile -> 934,...|# Indent Blanklin...|            NULL|        NULL|\n",
      "|           NeogitOrg|              neogit|{Ruby -> 67013, M...|<div align=\"cente...|            NULL|        NULL|\n",
      "|            sindrets|       diffview.nvim|{Makefile -> 814,...|# Diffview.nvim\\n...|            NULL|        NULL|\n",
      "|           jcjohnson|   fast-neural-style|{Shell -> 708, Lu...|# fast-neural-sty...|            NULL|        NULL|\n",
      "|       nvim-neo-tree|       neo-tree.nvim|{Dockerfile -> 73...|# Neo-tree.nvim\\n...|            NULL|        NULL|\n",
      "|            numToStr|        Comment.nvim|      {Lua -> 56571}|<h1 align=\"center...|            NULL|        NULL|\n",
      "|            CorsixTH|            CorsixTH|{Roff -> 3552, NS...|<picture>![image]...|            NULL|        NULL|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session with the MongoDB Spark Connector package\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"myApp\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"user\", StringType(), True),\n",
    "    StructField(\"repo\", StringType(), True),\n",
    "    StructField(\"mainLanguage\", StringType(), True),\n",
    "    StructField(\"languages\", MapType(StringType(), StringType()), True),\n",
    "    StructField(\"readme\", StringType(), True),\n",
    "    StructField(\"processed_readme\", StringType(), True),\n",
    "    StructField(\"last_updated\", TimestampType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read \\\n",
    "    .format(\"mongo\") \\\n",
    "    .option(\"database\", \"dev\") \\\n",
    "    .option(\"collection\", \"raw_data\") \\\n",
    "    .option(\"uri\", \"mongodb://mongo:27017/\") \\\n",
    "    .schema(schema) \\\n",
    "    .load()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in the dataframe: 9615\n"
     ]
    }
   ],
   "source": [
    "num_lines = df.count()\n",
    "print(f\"Number of lines in the dataframe: {num_lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connexion √† MongoDB\n",
    "client = pymongo.MongoClient(\"mongodb://mongo:27017/\")  \n",
    "db = client.get_database(\"dev\")\n",
    "collection = db.get_collection(\"raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La base de donn√©es existe.\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier si la base de donn√©es existe\n",
    "db_list = client.list_database_names()\n",
    "if \"dev\" in db_list:\n",
    "    print(\"La base de donn√©es existe.\")\n",
    "else:\n",
    "    print(\"La base de donn√©es n'existe pas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es depuis MongoDB\n",
    "def load_data_from_mongo():\n",
    "    data = list(collection.find())\n",
    "    texts = [item.get(\"readme_clean\", \"\") for item in data]\n",
    "    labels = [item.get(\"mainLanguage\", \"\") for item in data]\n",
    "    return texts, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger et pr√©parer les donn√©es\n",
    "texts, labels = load_data_from_mongo()\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Tokenisation des textes\n",
    "tokenized_texts = [word_tokenize(text) for text in texts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement du mod√®le Word2Vec\n",
    "word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour vectoriser les documents\n",
    "def vectorize_documents(tokenized_texts, model):\n",
    "    document_vectors = []\n",
    "    for tokens in tokenized_texts:\n",
    "        vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "        if vectors:\n",
    "            document_vectors.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            document_vectors.append(np.zeros(model.vector_size))\n",
    "    return document_vectors\n",
    "\n",
    "document_vectors = vectorize_documents(tokenized_texts, word2vec_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des donn√©es en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(document_vectors, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Ænement du classifieur\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:8090\")\n",
    "\n",
    "# Enregistrement du mod√®le dans MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.sklearn.log_model(classifier, \"random_forest_model\")\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestClassifier\")\n",
    "\n",
    "print(\"Mod√®le entra√Æn√© et enregistr√© dans MLflow !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
